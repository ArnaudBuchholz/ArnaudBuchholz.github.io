<script language="javascript" src="../include.js"></script>
<link rel="stylesheet" type="text/css" href="../file.css" />
<div class="post">
<h3 class="post-title entry-title">
    My own require implementation
</h3>
<div class="post-header">
    <div class="post-header-line-1"></div>
</div>
<div class="post-body">
<a href="#todo">&#128315;&#128317;&#128315;&#128317;&#128315;&#128317;&#128315;&#128317;&#128315;&#128317;&#128315;&#128317;&#128315;</a>
<!-- Copy from the next line -->
<div class="summary">
    <img src="http://ArnaudBuchholz.github.io/blog/student.png" align="left">
    The release 0.2.2 of GPF-JS delivers a polymorphic modularization mechanism that mimics RequireJS and CommonJS
    implementation of NodeJS. It was surprisingly easy to make it happen now that the library offers all the
    basic services and it combines lots of technologies. Here are the implementation details.
</div>
<code class="markdown">
## Introduction

The [GPF-JS release 0.2.2](https://github.com/ArnaudBuchholz/gpf-js/tree/v0.2.2) is finally
[out](https://gpf-js.blogspot.ca/2017/11/release-022-gpfrequire.html) and it contains
several improvements:
* Better code quality
* Better documentation
* Some tests were rewritten

(...) Actually, the GPF-JS is already in [version 0.2.3](https://github.com/ArnaudBuchholz/gpf-js/tree/v0.2.3) and
it [introduces stream piping](http://gpf-js.blogspot.ca/2017/12/release-023-streams-and-pipes.html).
But this article took me a very long time to finalize !

But the exciting part of it is the new [gpf.require](https://arnaudbuchholz.github.io/gpf/doc/gpf.require.html)
namespace that exposes a [modularization helper](https://arnaudbuchholz.github.io/gpf/doc/tutorial-REQUIRE.html).

To give a bit of context, the article will start by explaining how modularity helps developers create better code.
Then, a rapid overview of some existing modularization solutions will be covered.
Finally, the implementation as well as the future of gpf.require will be explored.

## Modularity

### One file to rule them all

![One File to bring them all and in the darkness bind them](https://arnaudbuchholz.github.io/blog/post/
My%20own%20require%20implementation/ring.png)

[In the Land of Mordor where the Shadows lie.](https://en.wikipedia.org/wiki/One_Ring)

To demonstrate the value of modularity, we will start with an extreme
[edge case](https://en.wikipedia.org/wiki/Edge_case): an application which source code stands in **one single file** and
a development team composed of **several developers**.
We will assume that **they all work simultaneously** and a version control system is used to store the file.

<svg width="100%" height="256"
     xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink">
    <defs>
        <marker id="head" orient="auto" markerWidth="2" markerHeight="4" refX="0.1" refY="2">
            <path d="M0,0 V4 L2,2 Z" fill="red" />
        </marker>
    </defs>
    <image xlink:href="http://ArnaudBuchholz.github.io/blog/coding.png" x="32" y="0" width="64px" height="64px"/>
    <image xlink:href="http://ArnaudBuchholz.github.io/blog/albert.png" x="0" y="0" width="64px" height="64px"/>
    <image xlink:href="http://ArnaudBuchholz.github.io/blog/document edit.png" x="96" y="16" width="32px" height="32px"/>
    <text x="106" y="34" text-anchor="middle">Z</text>
    <path
        marker-end="url(#head)"
        stroke-width="5" fill="none" stroke="red"
        d="M128,32 L232,104"
    />

    <image xlink:href="http://ArnaudBuchholz.github.io/blog/coding.png" x="32" y="64" width="64px" height="64px"/>
    <image xlink:href="http://ArnaudBuchholz.github.io/blog/britney.png" x="0" y="64" width="64px" height="64px"/>
    <image xlink:href="http://ArnaudBuchholz.github.io/blog/document edit.png" x="96" y="80" width="32px" height="32px"/>
    <text x="106" y="98" text-anchor="middle">Z</text>
    <path
            marker-end="url(#head)"
            stroke-width="5" fill="none" stroke="red"
            d="M128,96 L232,120"
    />

    <image xlink:href="http://ArnaudBuchholz.github.io/blog/coding.png" x="32" y="128" width="64px" height="64px"/>
    <image xlink:href="http://ArnaudBuchholz.github.io/blog/charles.png" x="0" y="128" width="64px" height="64px"/>
    <image xlink:href="http://ArnaudBuchholz.github.io/blog/document edit.png" x="96" y="144" width="32px" height="32px"/>
    <text x="106" y="162" text-anchor="middle">Z</text>
    <path
            marker-end="url(#head)"
            stroke-width="5" fill="none" stroke="red"
            d="M128,160 L232,136"
    />

    <image xlink:href="http://ArnaudBuchholz.github.io/blog/coding.png" x="32" y="192" width="64px" height="64px"/>
    <image xlink:href="http://ArnaudBuchholz.github.io/blog/denise.png" x="0" y="192" width="64px" height="64px"/>
    <image xlink:href="http://ArnaudBuchholz.github.io/blog/document edit.png" x="96" y="208" width="32px" height="32px"/>
    <text x="106" y="226" text-anchor="middle">Z</text>
    <path
            marker-end="url(#head)"
            stroke-width="5" fill="none" stroke="red"
            d="M128,224 L232,152"
    />

    <rect x="256" y="64" width="128px" height="128px" strike="black" fill="silver"></rect>
    <image xlink:href="http://ArnaudBuchholz.github.io/blog/cloud database.png" x="256" y="64" width="128px" height="128px"/>

    <path
            marker-end="url(#head)"
            stroke-width="5" fill="none" stroke="red"
            d="M400,128 L496,128"
    />

    <image xlink:href="http://ArnaudBuchholz.github.io/blog/document locked.png" x="512" y="96" width="64px" height="64px"/>
    <text x="534" y="116" text-anchor="middle">Z</text>

</svg>

(*Each developer works on a local copy of the source file and pushes to the file control system*)


The first obvious concern is the resulting file size. Depending on the application complexity, and assuming no library
is used, **the source file will be big**.

And with size comes additional problems, leading to [maintainability](https://en.wikipedia.org/wiki/Maintainability)
issues. Even if guidelines are well established between the team members and comments are used, **it will be hard to
navigate through the lines of code**.

JavaScript offer [hoisting](https://developer.mozilla.org/en-US/docs/Glossary/Hoisting) that basically allows the
developer to use a function before it is being declared.

`catName("Chloe");

function catName(name) {
  console.log("My cat's name is " + name);
}

// The result of the code above is: "My cat's name is Chloe"`

But most linters will raise [an error](https://eslint.org/docs/rules/no-use-before-define) for the above code.
Indeed, it is a best practice to declare functions and variables before using them.

So the team will end up **cluttering the source file** to ensure declarations are made before use.

Not being able to navigate easily in the code also generates a more subtle problem:
**some logic might be repeated because it was hard to locate**.

Finally, having all developers work on a single file will generate
**[conflicts](https://betterexplained.com/articles/a-visual-guide-to-version-control/)** when pushing it to the
[version control system](https://en.wikipedia.org/wiki/Version_control).
Fortunately, most of those systems have mechanism to solve the conflicts either automatically or with the help of the
developer. But **this takes developer time and it is not risk free**.

Obviously, all these problems may appear on smaller files too but, in general,
**the larger the file the more problems**.

Two questions are remaining:
* What could be the advantages of having a single source file?
* What is the maximum file size?

In the context of web applications, **a single source file makes the application load faster** as it reduces the number
of requests. It does not mean that it must be written manually, there are many tools capable of **building** it.

For instance:
* [UglifyJS](https://github.com/mishoo/UglifyJS2) is a command line tool that concatenates and
[minifies](https://en.wikipedia.org/wiki/Minification_%28programming%29) sources. It also exists as a
[grunt task](https://github.com/gruntjs/grunt-contrib-uglify).
* [Webpack](https://webpack.js.org/) goes even beyond JavaScript concatenation by handling resources and
[transpiling](https://www.stevefenton.co.uk/2012/11/compiling-vs-transpiling/) ES6 code.

Answering the second question is way more difficult.
From my experience, **any JavaScript source file bigger than 1000 lines is a problem**.
There might be good reasons to have a such a big file but it always comes with a cost.

In [GPF-JS](https://github.com/ArnaudBuchholz/gpf-js#metrics), the average number of lines per source file
is a little under 100. But it has not
[always been like this !](https://arnaudbuchholz.github.io/gpf/plato/index.html)

![Plato report on GPF-JS](https://arnaudbuchholz.github.io/blog/post/
My%20own%20require%20implementation/plato%20average%20lines.png)

### Divide and rule

![Or divide and conquer](https://arnaudbuchholz.github.io/blog/post/
My%20own%20require%20implementation/divide-and-conquer1.jpg)

Code splitting is a good illustration of the [divide and rule](https://en.wikipedia.org/wiki/Divide_and_rule)
principle. Indeed, **by slicing the application into smaller chunks, the developers have a better control over the
changes**.

<svg width="100%" height="256"
     xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink">
    <defs>
        <marker id="head" orient="auto" markerWidth="2" markerHeight="4" refX="0.1" refY="2">
            <path d="M0,0 V4 L2,2 Z" fill="red" />
        </marker>
    </defs>
    <image xlink:href="http://ArnaudBuchholz.github.io/blog/coding.png" x="32" y="0" width="64px" height="64px"/>
    <image xlink:href="http://ArnaudBuchholz.github.io/blog/albert.png" x="0" y="0" width="64px" height="64px"/>
    <image xlink:href="http://ArnaudBuchholz.github.io/blog/document edit.png" x="96" y="16" width="32px" height="32px"/>
    <text x="106" y="34" text-anchor="middle">A</text>
    <path
        marker-end="url(#head)"
        stroke-width="5" fill="none" stroke="red"
        d="M128,32 L232,104"
    />

    <image xlink:href="http://ArnaudBuchholz.github.io/blog/coding.png" x="32" y="64" width="64px" height="64px"/>
    <image xlink:href="http://ArnaudBuchholz.github.io/blog/britney.png" x="0" y="64" width="64px" height="64px"/>
    <image xlink:href="http://ArnaudBuchholz.github.io/blog/document edit.png" x="96" y="80" width="32px" height="32px"/>
    <text x="106" y="98" text-anchor="middle">B</text>
    <path
            marker-end="url(#head)"
            stroke-width="5" fill="none" stroke="red"
            d="M128,96 L232,120"
    />

    <image xlink:href="http://ArnaudBuchholz.github.io/blog/coding.png" x="32" y="128" width="64px" height="64px"/>
    <image xlink:href="http://ArnaudBuchholz.github.io/blog/charles.png" x="0" y="128" width="64px" height="64px"/>
    <image xlink:href="http://ArnaudBuchholz.github.io/blog/document edit.png" x="96" y="144" width="32px" height="32px"/>
    <text x="106" y="162" text-anchor="middle">C</text>
    <path
            marker-end="url(#head)"
            stroke-width="5" fill="none" stroke="red"
            d="M128,160 L232,136"
    />

    <image xlink:href="http://ArnaudBuchholz.github.io/blog/coding.png" x="32" y="192" width="64px" height="64px"/>
    <image xlink:href="http://ArnaudBuchholz.github.io/blog/denise.png" x="0" y="192" width="64px" height="64px"/>
    <image xlink:href="http://ArnaudBuchholz.github.io/blog/document edit.png" x="96" y="208" width="32px" height="32px"/>
    <text x="106" y="226" text-anchor="middle">D</text>
    <path
            marker-end="url(#head)"
            stroke-width="5" fill="none" stroke="red"
            d="M128,224 L232,152"
    />

    <rect x="256" y="64" width="128px" height="128px" strike="black" fill="silver"></rect>
    <image xlink:href="http://ArnaudBuchholz.github.io/blog/cloud database.png" x="256" y="64" width="128px" height="128px"/>

    <image xlink:href="http://ArnaudBuchholz.github.io/blog/document locked.png" x="422" y="48" width="64px" height="64px"/>
    <text x="444" y="68" text-anchor="middle">A</text>

    <image xlink:href="http://ArnaudBuchholz.github.io/blog/document locked.png" x="512" y="48" width="64px" height="64px"/>
    <text x="534" y="68" text-anchor="middle">B</text>

    <image xlink:href="http://ArnaudBuchholz.github.io/blog/document locked.png" x="422" y="144" width="64px" height="64px"/>
    <text x="444" y="164" text-anchor="middle">C</text>

    <image xlink:href="http://ArnaudBuchholz.github.io/blog/document locked.png" x="512" y="144" width="64px" height="64px"/>
    <text x="534" y="164" text-anchor="middle">D</text>

</svg>

(*Each developer works on separate - smaller - source files*)

It sounds easy but it is not.

When it comes to deciding how to slice the application and organize the sources,
there must be **rules and discipline**.

For example, maximizing the **level of granularity** by having one function per source will generate an overwhelming
amount of files. Also, **not having a clear file structure will make the architecture obscure** and will slow down the
team.

#### Files organization

There are many guidelines and howtos on the web depending on the type of project or technology.

For instance:
* [Best practices for Express app structure](https://www.terlici.com/2014/08/25/best-practices-express-structure.html)
* [AngularJS Best Practices: Directory Structure](https://scotch.io/tutorials/
angularjs-best-practices-directory-structure)
* [SAPUI5 application project structuring](http://www.sapui5tutors.com/2016/03/
sapui5-application-project-structuring.html)
* [Introduction to ExtJS Application Architecture](https://docs.sencha.com/extjs/6.0.0/guides/application_architecture/
application_architecture.html)
* [How to Structure Your React Project](https://daveceddia.com/react-project-structure/)

On the other hands, some tools offers the possibility to instantiate new projects with a predefined structure.
Such as [Yeoman](http://yeoman.io/) which contains [thousands of project generators](http://yeoman.io/generators/).

<iframe width="560" height="315" src="https://www.youtube.com/embed/zBt2g9ekiug" frameborder="0" allowfullscreen>
</iframe>

Yet, once the basic structure is in place, developers are still **confronted with choices when new files must be
created.**

So, regarding files organization, here are some basic principles (in no particular order):

* Document the structure and make it known: ask people to [Read The Fabulous Manual](https://en.wikipedia.org/wiki/RTFM)

* Folder names are used to qualify the files they contain.
Indeed, if a folder is named "controller", it is more than expected to find only
[controllers](https://en.wikipedia.org/wiki/Model–view–controller) in it.
The same way, for a web application, a "public" folder usually indicates that its content is exposed

* The folder qualification can be technical ("sources", "tests", "public") or functional ("controllers", "views",
"dialogs", "stream") but mixing at the same level should be avoided. For one technology stack, if dialogs are
implemented with controllers:
it makes sense to see "dialogs" below "controllers" but having both in the same folder will be confusing

* Try to stick to widely accepted (and understood) names: use "public" instead "www", use "dist" or "release" instead
of "shipping"...

* Try to avoid names that are too generic: "folder" *(true story)*, "misc", "util", "helpers", "data"...

* Stick to one language *(don't mix French and English)*


* Select and stick to a naming formalism, such as [Camel Case](https://en.wikipedia.org/wiki/Camel_case)

* Forget about the [8.3](https://en.wikipedia.org/wiki/8.3_filename) or
[MAX_PATH](https://support.microsoft.com/fr-ca/help/177665/path-too-long-error-message-when-exceeding-max-path)
limitations, names can be as long as necessary

![... and 640K is enough for everyone :-)](https://arnaudbuchholz.github.io/blog/post/
My%20own%20require%20implementation/back-in-my-day-funny-5.jpg)

#### Level of granularity

Once the structure is clearly defined, the only difficulty remaining is to figure out what to put inside the files.
Obviously, their names must be self explanatory about purpose and content.

**Struggling to choose the right file name is usually a good sign that it contains more than necessary**: splitting may
help.

In case of doubts, just associate:
* folders to [namespaces](https://en.wikipedia.org/wiki/Namespace)
* files to [classes](https://en.wikipedia.org/wiki/Class_%28computer_programming%29)

Then, try to stick to the [SOLID](https://en.wikipedia.org/wiki/SOLID_%28object-oriented_design%29)
![principles](https://arnaudbuchholz.github.io/blog/post/
My%20own%20require%20implementation/SOLID.jpg)

In particular, **the [Single Responsibility principle](https://en.wikipedia.org/wiki/Single_responsibility_principle)
should drive the choices when creating a new file**.

Here is a shamelessly modified copy of the wikipedia definition as it summarizes the idea:*

"The single responsibility principle is a computer programming principle that states that every module should have
responsibility over a single part of the functionality provided by the software, and that responsibility should be
entirely encapsulated by the module. All its services should be narrowly aligned with that responsibility."*


(...) Referring to the [Liskov substitution principle](https://en.wikipedia.org/wiki/Liskov_substitution_principle)
and the [Dependency inversion principle](https://en.wikipedia.org/wiki/Dependency_inversion_principle) may look weird
when considering source files but the following sections (in particular interface and mocking) will shed some light on
the analysis behind this statement.

Basically, because of this definition, a source file is no more a senseless bunch of lines of codes but rather a
**self-contained feature**. Hence, it will be referred as a **module**.

#### Modules

The advantages of modules are multiple:

* **Testability**: it is sometimes difficult to draw the line between
[unit testing](https://en.wikipedia.org/wiki/Unit_testing) and
[integration testing](https://en.wikipedia.org/wiki/Integration_testing). Long story short, if several modules are
needed to run a test, it sounds like integration. On the other hand, if the module can be tested with no or very few
dependencies (maybe through mocking), this is unit testing. So, ideally, **a module can be easily isolated to achieve
unit testing**

* **Maintainability**: on top of the testability, the file size should be relatively small. Both facts greatly increase
the module's [maintainability](https://en.wikipedia.org/wiki/Maintainability).
This means that **it is easier (in terms of complexity and effort) to improve or fix** the module.

* **Reusability**: no finger pointing here. Every developer starts his career by learning the 'virtues' of copy & paste.
It takes time and experience to realize that **[code duplication is evil](https://hethmonster.wordpress.com/2010/09/21/
duplicate-code-is-evil/)**. Modules are an indisputable alternative to copy & paste because **they are designed to be
reusable**.

### Loading

The way modules are loaded **varies for each host** and some examples will be shown in the 'Existing implementations'
section. This is where **GPF-JS brings value by offering one uniform solution** for all supported hosts.

The purpose of this part is not to explain each mechanism but rather describe the overall philosophy when it
comes to loading the sources of an application.

#### Everything at once

![Load all the files !](https://arnaudbuchholz.github.io/blog/post/
My%20own%20require%20implementation/X-All-The-Y.jpg)

As already mentioned before, there are tools designed to concatenate and minify all sources in order to generate
**a single application file**. The resulting file is consequently **self-sufficient** and can be easily loaded.

Dependencies will be addressed later but, to generate this file, the tool must know the list of files to
concatenate (or, usually, the folder where to find the files).

An alternative to load the application is to maintain a **list of sources to load**... in the correct order so that
**dependencies are loaded before their dependant modules**.

As a result, in an HTML page, a big list of [script](https://developer.mozilla.org/en-US/docs/Web/HTML/Element/script)
tags is required to include all sources.

For example, let consider the following modules: A, B, C, D, E and F
* A requires B and C to be loaded
* B requires D to be loaded
* E requires F to be loaded
* F can be loaded separately

The resulting ordered lists can be:
* D, B, C, A, F, E
* C, D, F, B, A, E
* F, D, C, B, A, E
* F, E, D, B, C, A
* ...

Advantages are:
* Sequence being managed by a list, it gives a **clear understanding of the loading process** and allows the developers
to fully control it
* Unlike the unique concatenated file that is regenerated for each release, some files might not even change between
versions. Consequently, **the loading process can benefit from caching mechanism** and the application starts faster.

Disadvantages are:
* Every time a new source is created, **it must be added to the list in the correct order** to be loaded
* **The more files, the bigger the list** (and the more complex to maintain)
* When the list becomes too big, one may loose track of which files are really required. In the worst situation, **some
may be loaded even if they are not used anymore**
* **Any change in dependencies implies a re-ordering of the list**

(...) This is not the preferred solution but this is how the source version of GPF-JS is
[handled](https://github.com/ArnaudBuchholz/gpf-js/blob/master/src/sources.json). The lazy me has created some tools
to maintain this list in the dashboard.

#### Lazy loading

Instead of loading all the files at once, another method consists in loading what is needed to **boot the
application** and then load **additional files when required**.
This is known as [lazy loading](https://en.wikipedia.org/wiki/Lazy_loading).

![Or the energy saving mode...](https://arnaudbuchholz.github.io/blog/post/
My%20own%20require%20implementation/lazy.jpg)

For each part of the loading process, the list of files to load must be maintained.
Hence the benefits are mostly focused on the **time needed to start the application**.

Back to the previous example, E and F are big files requiring lot of time to load and evaluate.
* Loading the application is done with the booting list: D, B, C, A
* And, when required, the feature implemented by E is loaded with: F, E

Advantages are:
* Faster startup of the application, it also implies **smaller initial
[application footprint](https://en.wikipedia.org/wiki/Application_footprint)**
* Loading instructions are split into smaller lists which are consequently **easier to maintain**

Disadvantages are:
* Once the application started, accessing a part that has not been previously loaded will **generate delay**
* If any trouble occurs during the additional loading phase (such as no network) **the application breaks**

#### Dependency management

Whether the application is based on static or lazy loading, both mechanism require lists of files to load.
However, **maintaining these lists is time consuming and error prone**.

![Is there any way to get rid of these lists?](https://arnaudbuchholz.github.io/blog/post/
My%20own%20require%20implementation/nolist.jpg)

It's almost impossible to get rid of the lists but **changing the scope** simplifies their management.
Instead of maintaining global lists of files to load, **each module can declare which subsequent modules it depends
on**. This way, when loading modules, **the loader must check dependencies and process them recursively**.

Hence, the whole application can be started by loading one module which depends on everything else. Also, it means that,
on top of implementing a feature, a module contains information about the way it should be loaded.

Back to the previous example:
* A contains information that B and C must be loaded
* B contains information that D must be loaded
* E contains information that F must be loaded
Then:
* Loading the application is done by loading A
* And, when required, the feature implemented by E is loaded with E

Advantages are:
* No big lists to maintain, **each module declare its dependencies** separately
* Better **visibility on module dependencies**
* Simplified **reusability** of modules
* **New files** are loaded if declared as dependencies
* Only **required files** are loaded

Disadvantages are:
* **Loading a module is more complex**: dependencies must be extracted and resolved recursively
* Having such a fine level of granularity increases the **risk of tangled dependencies** and, in the worst case,
deadlocks. For instance, three modules: A, B and C. If A depends on B, B depends on C and C depends on A, it is
impossible to load any of them.
* If one module is a common dependency to several other modules, **it has to be loaded only once**. If not, the loading
performances will be decreased because of multiple loading of the same module

(...) Obviously, for the last part, the loading mechanism must handle some kind of caching.

### Interface

Assuming modules have information about their dependencies, how do they access the features being exposed?

#### Global variables

There are many mechanism but the simplest one is to alter the
[global scope](https://developer.mozilla.org/en-US/docs/Web/JavaScript/Guide/Grammar_and_types#Variable_scope) to export
functions and variables.

Indeed, in a flat module, declaring functions and variables is enough to make them **available globally** in the
application.

`// No dependencies
var ANY_CONSTANT = "value";

function myExportedFunction () {
    /* ...implementation... */
}`

(...) To be precise, this depends on the host and how the module is loaded. Let's stay simple for now.

The main advantage is **simplicity**.

However, problems occur as soon as the complexity of the module grows.

In fact, the module may also declare functions and variables that are used internally and those **implementation details
should not be exposed**. With the above mechanism, it is almost impossible to guarantee that they won't be accessed
*(or, worst, altered)* and, consequently, it creates
**tight [coupling](https://en.wikipedia.org/wiki/Loose_coupling#In_programming)** with the rest of the application.

This means that it gives less flexibility when it comes to maintaining the module.

One easy [workaround](https://en.wikipedia.org/wiki/Workaround) consists in encapsulating these implementation details
inside a **private scope** using an
[Immediately Invoked Function Expression](https://en.wikipedia.org/wiki/Immediately-invoked_function_expression).

`// No dependencies
var ANY_CONSTANT = "value",
    myExportedFunction;

// IIFE
(function () {
    "use strict";

    // Begin of private scope

    // Any functions or variables declared here are 'private'

    // Reveal function
    myExportedFunction = function () {
       /* ...implementation... */
    }

    // End of private scope
}());`

Another aspect that should be considered when dealing with globals is
**[name collisions](https://en.wikipedia.org/wiki/Name_collision)**. This can be quickly adressed with
**[namespaces](https://en.wikipedia.org/wiki/Namespace)** but here comes a challenging example.

#### Module interface

Let's consider an application capable of loading and saving documents.
Developers were smart enough to isolate the serialization part inside a module which exposes two methods: save and load.
The application grows in functionality and, for some reasons, saving and loading evolve to a new format.
Still, for backward compatibility reasons, the application should be able to load older documents.

At that point, there are several possibilities:

* Changing the code to support both formats in one function is not an option: for the sake of **maintainability**, there
must be a wrapper function to detect the format and then switch to the proper implementation.

* **Rename** the save and load methods to include a version number (for instance: saveV1, loadV1, saveV2 and loadV2).
Then the code *(production and test)* must be modified to use the proper method depending on the format that needs to be
serialized.

* **Create a namespace** for each version and have the methods being set inside the proper namespace: app.io.v1.save,
app.io.v1.load, app.io.v2.save and app.io.v2.load. Again, the code must be adapted but provided the **namespace can be a
parameter** (thanks to JavaScript
where [namespaces are objects](https://javascriptweblog.wordpress.com/2010/12/07/namespacing-in-javascript/)), this
reduces the cost.

* **Define an interface** and have one module per version that exposes this interface. It's almost like with
namespacing but accessing the proper object does not depend on global naming but rather on **loading the right module**.

For instance:
`var currentVersion = 2,
    io = loadModule("app/io/v" + currentVersion);

// io exposes save and load methods

function save (fileName) {
    // Always save with the lastest version
    return io.save(fileName);
}

function load (fileName) {
    var version = detect(fileName);
    if (version !== currentVersion) {
        return loadModule("app/io/v" + version).load(fileName);
    }
    return io.load(fileName);
}`

The impact of the next version is limited to changing the name of the module.
Remember lazy loading? This is an example where the oldest versions are loaded only when needed (reducing the
application footprint on startup).

So, ideally, on top of providing dependency information, the module also **exposes a known
[interface](https://en.wikipedia.org/wiki/Application_programming_interface)**. It defines the expectations regarding
the methods and variables that will be available and simplifies its integration and reusability.

### Module loader

To summarize what has been presented so far:
* An application is composed of modules, they are **smaller parts encapsulating single functionalities**
* To simplify the loading of the application, **modules declares their list of dependencies**
* Loading the module gives access to a **given set of API a.k.a. interface**

Consequently, the ultimate module loader is capable of extracting and resolving dependencies. Then it uses
[dependency injection](https://en.wikipedia.org/wiki/Dependency_injection) to give access to the interfaces exposed by
its dependencies.

### Mocking

Another subtle benefit of modularity is related to unit testing.

Coming back to the example of module B requiring module D to be loaded: what if module D can't be loaded or used in a
test environment? This module might require critical resources. For instance it could access a database and alter its
content: nobody wants the tests to mess with real data.

Does this mean that module B can't be tested because module D is not testable?

Well, assuming that module D is exposing a well defined interface and provided that the modularization system offers a
way to substitute a module by another one, it is possible to create a **fake module that exposes the same interface**
but **mocking the functionalities**.

## Existing implementations

### Browser includes

The simples way to include a JavaScript source in an HTML page is to add a
[script tag](https://developer.mozilla.org/en-US/docs/Web/HTML/Element/script).

Even though **loading is asynchronous**, and unless the attributes *async* or *defer* are specified, **scripts are
evaluated in the same order as they are declared** in the page.

By default, the scope of evaluation is global. Consequently, **any variable declaration is globally available** as if it
was a member of the [window object](https://developer.mozilla.org/en-US/docs/Web/API/Window).

As explained before, it is possible to create a **private scope using an IIFE**. Exposing the module interface can be
done through **assigning new members to the window object** or using *this* in the IIFE.

Here is a small variation to make the exported API more explicit:

`(function (exports) {
    "use strict";

    // Begin of private scope

    // Any functions or variables declared here are 'private'

    // Reveal function
    exports.myExportedFunction = function () {
       /* ...implementation... */
    }

    // End of private scope
}(this));`

In this context, declaring or loading dependencies inside a module becomes quite complex.
Indeed, it is possible to generate script tags using JavaScript (or use AJAX requests) but the code
must wait for the subsequent script to be loaded.

### RequireJS

The [RequireJS](http://requirejs.org/) library was originally created for browsers but also works with other hosts (in
particular Rhino).

By offering a unique mechanism to **load and inject modules**, this helper solves all the problems of modularization.
The **factory function** generates a private scope and receives the injected dependencies as parameters.

`define(["dependency"], function (dependency) {
    "use strict";

    // Begin of private scope

    // Any functions or variables declared here are 'private'

    // Reveal function
    return {
        myExportedFunction: function () {
            /* ...implementation... */
        }
    };

    // End of private scope
});`

The article ["Understanding RequireJS for Effective JavaScript Module Loading"](https://www.sitepoint.com/
understanding-requirejs-for-effective-javascript-module-loading/) covers all the steps to start with the library.

### NodeJs

[NodeJS](https://en.wikipedia.org/wiki/Node.js) offers a modularization helper initially inspired from
[CommonJS](https://en.wikipedia.org/wiki/CommonJS).

Loading a module is as easy as calling the [require](https://nodejs.org/api/modules.html#modules_require) function:
**loading is synchronous**. The same way, the module can load its dependencies using require.

**Modules have a private scope**. If the global scope must be altered *(which is not recommended)*, the **global
symbol** is available.
But the normal way to expose the module API is to assign members to the **module.exports** object (the shortcut exports
can also be used).

A typical module would look like:

`"use strict";

// Begin of private scope

// Any functions or variables declared here are 'private'

var dependency = require("dependency");

// Reveal function
module.exports = {
    myExportedFunction = function () {
        /* ...implementation... */
    }
};

// End of private scope`

Actually, there are two types of modules.

#### NPM modules

The [NPM repository](https://www.npmjs.com/) stores a huge collection of modules which can be **downloaded and updated**
using the [NPM](https://en.wikipedia.org/wiki/Npm_%28software%29) command line (installed with NodeJS).
These modules are usually defined as **project dependencies** through the
[package.json](https://docs.npmjs.com/files/package.json) file or they can be globally installed.

When loading these modules, **they are referenced by an absolute name**.

For instance, the [GPF-JS NPM module](https://www.npmjs.com/package/gpf-js), once installed, can be loaded with:
`var gpf = require("gpf-js");`

You can [experiment it](https://runkit.com/npm/gpf-js) yourself.

#### Local modules

On the other hand, the project may contain its own set of modules: they don't need to be published to be located.
In order to load a local modules, **the path to the source file must be provided**,
it is **relative to the current module**.

`var CONST = require("./const.js");`

### Bundlers

A [JavaScript bundler](https://medium.com/@gimenete/how-javascript-bundlers-work-1fc0d0caf2da) is a tool designed to
concatenate an application composed of modules (and resources) into a single self-sufficient and easy-to-load file.

The good parts are:
* it enforces code reuse by **enabling modularization when developping**
* it **speeds up the application loading** by limiting the number of files
* by relying on the dependence tree, it also **trims files which are never loaded**

The bad parts are:
* The generated code is usually **obfuscated**, debugging might be complicated

(...) Some bundlers are capable of generating the
[source map](https://developer.mozilla.org/en-US/docs/Tools/Debugger/How_to/Use_a_source_map) information. This helps
a lot when debugging but the source code must be exposed.

* The application file must be **generated before running the application**.
Depending on the number of files it might take some time

#### Browserify

[Browserify](http://browserify.org/) is a bundler understanding the **NodeJS require syntax** and capable of collecting
all JavaScript dependencies to generate **one single file loadable in a browser** (hence the name).

#### WebPack

[WebPack](https://webpack.js.org/) is like browserify on steroids as it does more than just collecting and packing
JavaScript dependencies. It is also capable of embedding **resource files** such as images, sounds...

The [bubu-timer project](https://github.com/ArnaudBuchholz/bubu-timer) is based on WebPack.

#### Others

Some [transpilers](https://scotch.io/tutorials/javascript-transpilers-what-they-are-why-we-need-them) are also bundlers:
* [Babel](https://babeljs.io/) which understands [ES6](https://developer.mozilla.org/en-US/docs/Web/JavaScript/
New_in_JavaScript/ECMAScript_2015_support_in_Mozilla)
* [CoffeeScript](http://coffeescript.org/), a sort of intermediate language compiled into JavaScript
* [Typescript](http://www.typescriptlang.org/), which can be *extremely summarized* by JavaScript with type checking

If you plan to use one or the other, the following reading are recommended:
* [Browserify VS Webpack - JS Drama](http://blog.namangoel.com/browserify-vs-webpack-js-drama)
* [Understanding JavaScript Modules: Bundling & Transpiling](https://www.sitepoint.com/
javascript-modules-bundling-transpiling/)

<a name="todo">&#128315;&#128317;&#128315;&#128317;&#128315;&#128317;&#128315;&#128317;&#128315;&#128317;&#128315;&#128317;&#128315;</a>

### Javascript import

There is no way this article could talk about JavaScript modularization without referring to the latest EcmaScript
[import feature](https://developer.mozilla.org/en-US/docs/Web/JavaScript/Reference/Statements/import).

It is fully supported by transpilers and bundlers (such as TypeScript, Babel, Webpack...) and native implementation

NodeJS also supports the [import feature](https://nodejs.org/api/esm.html#esm_notable_differences_between_import_and_require).

## GPF-JS Implementation

### Context switching

require.define is redefined

### File loading

Switch between web and non web
    gpf.http.get / gpf.fs.load


### Caching

Caching the promises
Cache modification handler

### Detecting resource type

By file extension

### JavaScript module execution

Detecting module type
    Based on a regular expression to detect the use of require

    => Should probably be testing module.exports too...

Dealing with inner promises

If the module also uses gpf.require.define OR define itself, you must wait for this function to complete before
    completing the loading of the module (so that it can be used).
This was quite challenging but I found using promise wrapping

## Future of gpf.require

### Handling cross references

(See how NodeJS and RequireJS handle them)

Pattern by setting the dependency
Principle of weak references: can be resolved after the module was loaded


## Conclusion

Things to improve:
    - detect cross references
    - implement new file types (templates?)
    - implement module properties & hidden variables (https://nodejs.org/docs/latest/api/modules.html#modules_module_children)

</code>
<!-- Drop those two lines -->
</div>
</div>
